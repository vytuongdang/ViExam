# ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?

This repository contains the official codebase and dataset generation pipeline for **ViExam**, the first Vietnamese multimodal exam benchmark for evaluating Vision-Language Models (VLMs). The benchmark consists of **2,548 genuine multimodal exam questions** across 7 domains:

> Mathematics, Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test.

---

## üß™ Dataset Overview

| Subject      | #Questions |
| ------------ | ---------- |
| Mathematics  | 456        |
| Physics      | 361        |
| Chemistry    | 302        |
| Biology      | 341        |
| Geography    | 481        |
| Driving Test | 367        |
| IQ Test      | 240        |
| **Total**    | **2,548**  |

> Each question is an image containing both Vietnamese text and visuals. Most are 4-option multiple-choice questions. No screenshots of text-only questions are included ‚Äî all questions are genuinely **multimodal**.

---

## üß∞ Repository Structure

```
.
üïú‚îÄ‚îÄ api_code/
‚îÇ   ‚îú‚îÄ‚îÄ api_handlers/          # API wrapper for VLMs (e.g., Claude, Gemini, OpenAI)
‚îÇ   ‚îú‚îÄ‚îÄ main_api.py            # Main API call logic
‚îÇ   ‚îú‚îÄ‚îÄ backup_api_code/       # Backup or legacy code
‚îÇ   ‚îî‚îÄ‚îÄ main_api_qwen.py
‚îÇ
üïú‚îÄ‚îÄ api_key/                   # API credentials (plaintext)
‚îÇ   ‚îú‚îÄ‚îÄ claude_key.txt
‚îÇ   ‚îú‚îÄ‚îÄ openai_key.txt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
üïú‚îÄ‚îÄ batch_api_code/            # Batch processing for large-scale evaluation
‚îÇ   ‚îú‚îÄ‚îÄ main_batch_api.py
‚îÇ   ‚îú‚îÄ‚îÄ main_batch_prepare.py
‚îÇ   ‚îî‚îÄ‚îÄ handlers/
‚îÇ
üïú‚îÄ‚îÄ src/                       # Full pipeline for data extraction and preprocessing
    ‚îú‚îÄ‚îÄ test_cut_question.py   # Image cutting logic
    ‚îú‚îÄ‚îÄ convert_pdf_to_image.py
    ‚îú‚îÄ‚îÄ check_question.html   # Evaluation parsing
    ‚îú‚îÄ‚îÄ result.py       # Accuracy tables
    ‚îî‚îÄ‚îÄ ...
```

---

## üöÄ Quickstart

### 1. Install requirements

```bash
pip install -r src/requirements.txt
```

### 2. Run evaluation on VLMs

```bash
python batch_api_code/main_batch_api.py
```

Or for individual models:

```bash
python api_code/main_api.py --model gpt-4
```

### 3. Analyze results

```bash
python src/result.py
```

---

## ‚úÇÔ∏è Dataset Preparation Pipeline

Full multimodal exam questions are extracted from real Vietnamese exams using:

* PDF ‚Üí PNG conversion
* OCR + heuristics to detect question/image boundaries
* Geometric filtering to exclude text-only items
* Manual verification by Vietnamese native speakers (3x agreement)

> See `src/test_cut_question.py` for more.

---

## ‚úèÔ∏è Human-in-the-loop Enhancement

We provide a web-based tool for:

* Editing OCR results
* Verifying model descriptions
* Exporting ground truth data

---

## üìä Evaluation Protocol

* Evaluation across **7 subject domains**
* Models tested:

  * GPT-4.1, Claude-Sonnet-4, Gemini 2.5 Flash, o3
  * Aya Vision, Gemma, Mistral, LLaMA 4, Qwen
* OCR benchmark for Vietnamese
* Option distribution bias analysis
* Cross-lingual prompting (Vietnamese vs English)
* Text-only vs multimodal comparison